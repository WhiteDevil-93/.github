name: Jules Integration - Enhanced Autonomy

on:
  push:
    branches: [main]
    paths:
      - '**.py'
      - '**.md'
      - '**.yml'
      - '**.yaml'
      - 'requirements.txt'
      - 'package.json'
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:
    inputs:
      scope:
        description: 'Analysis scope (full, incremental)'
        required: false
        default: 'incremental'
        type: choice
        options:
          - full
          - incremental
      model:
        description: 'AI model for analysis'
        required: false
        default: 'minimax-m2.1'
        type: choice
        options:
          - minimax-m2.1
          - gemini-pro
          - claude-3-opus

# Prevent concurrent runs
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  trigger-jules-autonomous:
    name: Autonomous Jules Trigger
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      contents: read
      pull-requests: write
    if: github.event_name == 'pull_request'
    outputs:
      trigger_status: ${{ steps.trigger.outputs.trigger_status }}
      diff_stats: ${{ steps.trigger.outputs.diff_stats }}
      artifact_count: ${{ steps.trigger.outputs.artifact_count }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: false

      - name: Generate intelligent diff summary
        id: trigger
        run: |
          echo "ðŸ“Š Generating diff summary..."
          TRIGGER_STATUS="success"
          
          # Get diff statistics
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            git fetch origin "${{ github.event.pull_request.base.ref }}" 2>/dev/null || true
            DIFF_STATS=$(git diff --stat "origin/${{ github.event.pull_request.base.ref }}...HEAD" 2>/dev/null || git diff --stat HEAD~1..HEAD)
          else
            DIFF_STATS=$(git diff --stat HEAD~1..HEAD)
          fi
          
          # Count changed files
          CHANGED_FILES=$(echo "$DIFF_STATS" | wc -l)
          echo "diff_stats=$DIFF_STATS" >> $GITHUB_OUTPUT
          echo "changed_files=$CHANGED_FILES" >> $GITHUB_OUTPUT
          
          if [[ -n "$DIFF_STATS" ]]; then
            echo "âœ… Diff statistics generated"
          else
            echo "âš ï¸  No diff detected"
            TRIGGER_STATUS="no_changes"
          fi
          
          echo "trigger_status=$TRIGGER_STATUS" >> $GITHUB_OUTPUT

      - name: Create intelligent Jules prompt
        run: |
          echo "ðŸ“ Creating Jules analysis prompt..."
          
          SCOPE="${{ github.event.inputs.scope || 'incremental' }}"
          MODEL="${{ github.event.inputs.model || 'minimax-m2.1' }}"
          
          # Create comprehensive prompt
          cat > .jules-prompt.md << EOF
# Themyscira Code Review Request - Enhanced

## Project Context
**Themyscira** - A modular, agent-based AI system built on **Ollama** with **MiniMax** as the primary orchestration framework.

## Core Agents Architecture
- **Hippolyta** - Orchestrator / Governor
- **Diana** - Primary Reasoner (Large Model)
- **Nubia** - Challenger / Second Opinion
- **Artemis** - Execution Agent
- **Antiope** - Code & Combat Specialist
- **Philippus** - Security & Permissions
- **Io** - Builder & Integrations
- **Menalippe** - Knowledge Curator
- **Aella** - Scout / Web Retriever
- **Penthesilea** - Stress & Load Controller
- **Alkyone** - Memory Keeper
- **Callisto** - Notebook & UX Layer

## Enhanced Review Focus Areas
1. **Architecture Compliance** - Does the code follow the agent-based modular design?
2. **Ollama Integration** - Are model interactions properly abstracted?
3. **MiniMax Framework Usage** - Are agents, tools, and webhooks used correctly?
4. **Security** - OAuth handling, secrets management, permissions
5. **Testing** - Coverage and test quality
6. **Documentation** - Docstrings, README, architecture docs
7. **Performance** - Resource usage, response times
8. **Maintainability** - Code complexity, dependencies

## Analysis Parameters
- **Scope:** $SCOPE
- **Model:** $MODEL
- **Focus:** Architecture, Security, Performance

## Changes Summary
${{ steps.trigger.outputs.diff_stats }}

## Output Format
Provide analysis in Markdown with:
1. Executive Summary
2. Architecture Assessment
3. Security Analysis
4. Performance Evaluation
5. Compliance Checklist
6. Actionable Recommendations
EOF
          
          echo "âœ… Jules prompt created"

      - name: Upload artifacts for Jules
        uses: actions/upload-artifact@v4
        with:
          name: jules-input-enhanced
          path: |
            .jules-prompt.md
            themyscira/
            tests/
            docs/

      - name: Create Jules comment
        uses: actions/github-script@v7
        with:
          script: |
            const scope = '${{ github.event.inputs.scope || "incremental" }}';
            const model = '${{ github.event.inputs.model || "minimax-m2.1" }}';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `ðŸ¤– **Enhanced Jules Code Review Request**\n\n` +
                `ðŸ” Jules Analysis Triggered\n\n` +
                `ðŸ“‹ **Configuration:**\n` +
                `- Scope: ${scope}\n` +
                `- Model: ${model}\n\n` +
                `ðŸŽ¯ **Review Focus:**\n` +
                `- Architecture compliance verification\n` +
                `- Ollama model integration validation\n` +
                `- MiniMax framework best practices\n` +
                `- Security and permissions audit\n` +
                `- Code quality and performance\n\n` +
                `â³ Awaiting enhanced analysis report...`
            });

  jules-validation-autonomous:
    name: Autonomous Jules Validation
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: trigger-jules-autonomous
    outputs:
      validation_status: ${{ steps.validate.outputs.validation_status }}
      agents_found: ${{ steps.validate.outputs.agents_found }}
      compliance_score: ${{ steps.validate.outputs.compliance_score }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Download Jules input artifacts
        uses: actions/download-artifact@v4
        with:
          name: jules-input-enhanced
          path: jules-input/

      - name: Generate comprehensive analysis
        id: validate
        run: |
          echo "ðŸ” Running autonomous validation..."
          
          VALIDATION_STATUS="success"
          AGENTS_FOUND=""
          COMPLIANCE_SCORE=0
          
          python << EOF
import json
from pathlib import Path
from datetime import datetime

# Analysis configuration
ANALYSIS_SCOPE = "${{ github.event.inputs.scope || 'incremental' }}"

# Initialize report
report = {
    "timestamp": datetime.utcnow().isoformat() + "Z",
    "repository": "${{ github.repository }}",
    "analysis_scope": ANALYSIS_SCOPE,
    "files_analyzed": [],
    "agents_found": [],
    "compliance_status": {},
    "recommendations": [],
    "security_findings": [],
    "performance_metrics": {}
}

# Analyze code structure
themyscira_path = Path("jules-input/themyscira/")
agents = [
    "hippolyta", "diana", "nubia", "artemis", "antiope", 
    "philippus", "io", "menalippe", "aella", "penthesilea", 
    "alkyone", "callisto"
]

# Check for agent implementations
for agent in agents:
    agent_file = themyscira_path / f"{agent}.py"
    if agent_file.exists():
        report["agents_found"].append(agent)
        report["files_analyzed"].append(str(agent_file))

# Analyze all Python files
if themyscira_path.exists():
    for py_file in themyscira_path.rglob("*.py"):
        report["files_analyzed"].append(str(py_file))

# Compliance checks
report["compliance_status"] = {
    "modular_architecture": len(report["agents_found"]) > 0,
    "ollama_integration": any("ollama" in str(f).lower() for f in report["files_analyzed"]),
    "minimax_framework": any("minimax" in str(f).lower() for f in report["files_analyzed"]),
    "documentation": Path("jules-input/docs/").exists(),
    "tests": Path("jules-input/tests/").exists(),
    "security_implementation": any("security" in str(f).lower() or "auth" in str(f).lower() for f in report["files_analyzed"])
}

# Calculate compliance score
checks_passed = sum(1 for v in report["compliance_status"].values() if v)
total_checks = len(report["compliance_status"])
report["compliance_score"] = round((checks_passed / total_checks) * 100, 2)

# Generate recommendations
report["recommendations"] = [
    f"Review Hippolyta orchestrator for proper task routing (Agents found: {len(report['agents_found'])})",
    "Ensure Diana has proper model configuration and error handling",
    "Validate Antiope code specialist integration",
    "Check Philippus security implementation for OAuth compliance"
]

# Security findings
report["security_findings"] = [
    {"severity": "info", "message": "Review OAuth implementation in Philippus"},
    {"severity": "info", "message": "Verify secrets management in environment configuration"}
]

# Performance metrics
report["performance_metrics"] = {
    "files_analyzed": len(report["files_analyzed"]),
    "agents_implemented": len(report["agents_found"]),
    "architecture_compliance": report["compliance_score"]
}

# Save report
with open("jules-report.json", "w") as f:
    json.dump(report, f, indent=2)

print(f"âœ… Analysis complete")
print(f"   Files analyzed: {len(report['files_analyzed'])}")
print(f"   Agents found: {len(report['agents_found'])}")
print(f"   Compliance score: {report['compliance_score']}%")
EOF
          
          # Extract outputs
          AGENTS_FOUND=$(python -c "import json; print(','.join(json.load(open('jules-report.json'))['agents_found']))" 2>/dev/null || echo "none")
          COMPLIANCE_SCORE=$(python -c "import json; print(json.load(open('jules-report.json'))['compliance_score'])" 2>/dev/null || echo "0")
          
          echo "agents_found=$AGENTS_FOUND" >> $GITHUB_OUTPUT
          echo "compliance_score=$COMPLIANCE_SCORE" >> $GITHUB_OUTPUT
          echo "validation_status=$VALIDATION_STATUS" >> $GITHUB_OUTPUT

      - name: Upload Jules report
        uses: actions/upload-artifact@v4
        with:
          name: jules-report-enhanced
          path: |
            jules-report.json
            jules-input/

      - name: Validate compliance
        run: |
          echo "âœ… Compliance validation complete"
          python << EOF
import json

with open("jules-report.json") as f:
    report = json.load(f)

print("\nðŸ“Š Compliance Report:")
for check, passed in report["compliance_status"].items():
    status = "âœ…" if passed else "âŒ"
    print(f"   {status} {check}: {'PASS' if passed else 'FAIL'}")

print(f"\nðŸŽ¯ Overall Compliance Score: {report['compliance_score']}%")
EOF

  publish-results-autonomous:
    name: Publish Jules Results
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: jules-validation-autonomous
    if: github.event_name == 'pull_request'
    steps:
      - name: Download Jules report
        uses: actions/download-artifact@v4
        with:
          name: jules-report-enhanced
          path: reports/

      - name: Comment on PR with enhanced results
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = JSON.parse(fs.readFileSync('reports/jules-report.json', 'utf8'));
            
            const agents = report.agents_found.join(', ') || 'None';
            const score = report.compliance_score;
            
            let scoreEmoji = 'ðŸŸ¢';
            if (score < 50) scoreEmoji = 'ðŸ”´';
            else if (score < 80) scoreEmoji = 'ðŸŸ¡';
            
            let comment = `## ðŸ” Enhanced Jules Analysis Report\n\n`;
            comment += `**Analysis Date:** ${report.timestamp}\n`;
            comment += `**Scope:** ${report.analysis_scope}\n`;
            comment += `**Files Analyzed:** ${report.files_analyzed.length}\n`;
            comment += `**Agents Found:** ${agents}\n\n`;
            
            comment += `### ${scoreEmoji} Compliance Score: ${score}%\n\n`;
            comment += `### Compliance Status\n`;
            for (const [check, passed] of Object.entries(report.compliance_status)) {
                const icon = passed ? 'âœ…' : 'âŒ';
                comment += `${icon} ${check}\n`;
            }
            
            if (report.recommendations.length > 0) {
                comment += `\n### Recommendations\n`;
                report.recommendations.forEach(rec => {
                    comment += `- ${rec}\n`;
                });
            }
            
            if (report.security_findings && report.security_findings.length > 0) {
                comment += `\n### Security Findings\n`;
                report.security_findings.forEach(finding => {
                    comment += `- [${finding.severity.toUpperCase()}] ${finding.message}\n`;
                });
            }
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
